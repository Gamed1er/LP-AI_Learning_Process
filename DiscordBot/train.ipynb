{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XPaKw5YGwXd"
      },
      "source": [
        "# DiscordBot x AI智能\n",
        "此處為Discord Bot x AI客服機器人的程式演示\n",
        "由於部分原始碼遺失，僅展示訓練的部分\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGUaLm2SJx_-"
      },
      "source": [
        "## 1.設定/訓練模組\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ckiptagger import data_utils, construct_dictionary, WS, POS, NER\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#模型下載\n",
        "try:\n",
        "    f = open('data.zip','r')\n",
        "    print(\"成功讀取 data.zip 檔案\")\n",
        "    f.close()\n",
        "except:\n",
        "    print(\"未讀取到 data.zip 檔案，正在重新下載...\")\n",
        "    data_utils.download_data_gdown(\"./\")\n",
        "finally:\n",
        "    wsmodel = WS(\"./data\")\n",
        "    posmodel = POS(\"./data\")\n",
        "    nermodel = NER(\"./data\")\n",
        "print(\"設定 ws,pos,ner 成功\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rac7DTVslJb",
        "outputId": "75cb4c65-ea1b-4ad3-cec3-d3146cefdfb4"
      },
      "outputs": [],
      "source": [
        "\n",
        "#斷詞模型\n",
        "def cutwords(sentence_list):\n",
        "    global wsmodel,posmodel,nermodel\n",
        "    ws = wsmodel\n",
        "    pos = posmodel\n",
        "    ner = nermodel\n",
        "    #斷詞\n",
        "    word_sentence_list = ws(\n",
        "        sentence_list,\n",
        "        sentence_segmentation = True, # To consider delimiters\n",
        "        segment_delimiter_set = {\",\", \"。\", \":\", \"?\", \"!\", \";\", \"，\",\"「\",\"」\"} # This is the defualt set of delimiters\n",
        "        # recommend_dictionary = dictionary1, # words in this dictionary are encouraged\n",
        "        # coerce_dictionary = dictionary2, # words in this dictionary are forced\n",
        "    )\n",
        "    #斷詞語法\n",
        "    pos_sentence_list = pos(word_sentence_list)\n",
        "    #斷詞增測到的 tag (暫時不會使用到)\n",
        "    entity_sentence_list = ner(word_sentence_list, pos_sentence_list)\n",
        "    #準備輸出陣列\n",
        "    assert len(word_sentence_list) == len(pos_sentence_list)\n",
        "\n",
        "    sentence_list_output = []\n",
        "    for i in range(len(sentence_list)):\n",
        "        for word,pos in zip(word_sentence_list[i],pos_sentence_list[i]):\n",
        "            sentence_list_output.append(f\"{word}({pos})\")\n",
        "    del ws,pos,ner\n",
        "    return sentence_list_output\n",
        "\n",
        "#詞帶模型\n",
        "def bag_of_words(tokenized_sentence, all_words):\n",
        "\n",
        "    bag = np.zeros(len(all_words),dtype=np.float32)\n",
        "\n",
        "    for idx, w in enumerate(all_words):\n",
        "        if w in tokenized_sentence:\n",
        "            bag[idx] = 1.0\n",
        "    return bag\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 打開文字資料檔\n",
        "try:\n",
        "    with open('intents.json','r') as f:\n",
        "        intents_box = json.load(f)\n",
        "except:\n",
        "    intents_box = intents_box\n",
        "\n",
        "#引入學習過的模型\n",
        "FILE = 'data.pth'\n",
        "data = torch.load(FILE)\n",
        "input_size = data[\"input_size\"]\n",
        "hidden_size = data[\"hidden_size\"]\n",
        "output_size = data[\"output_size\"]\n",
        "all_words = data['all_words']\n",
        "tags = data['tags']\n",
        "model_state = data[\"model_state\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#讀取json\n",
        "try:\n",
        "    with open('intents.json','r') as f:\n",
        "        intents_box = json.load(f)\n",
        "except:\n",
        "    print(\"讀取intents.json失敗，將使用預設測試資料\")\n",
        "\n",
        "#處理檔案\n",
        "all_words = []\n",
        "tags = []\n",
        "xy = []\n",
        "\n",
        "for intent in intents_box['intents_list']:\n",
        "    tag = intent['tag']\n",
        "    tags.append(tag)\n",
        "\n",
        "    for sentence in intent['patterns']:\n",
        "        tsave = cutwords([str(sentence)])\n",
        "        all_words.extend(tsave)\n",
        "        xy.append((tsave,tag))\n",
        "all_words = sorted(set(all_words))\n",
        "tags = sorted(set(tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#訓練檔案處理\n",
        "X_train = [] #輸入: BOW向量\n",
        "y_train = [] #輸出: 儲存tag(分類)\n",
        "\n",
        "for (sentence, tag) in xy:\n",
        "    bag = bag_of_words(sentence,all_words)\n",
        "    X_train.append(bag)\n",
        "\n",
        "    label = tags.index(tag)\n",
        "    y_train.append(label)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Pytorch神經網路設定 (Hyperparameter)\n",
        "batch_size = 8\n",
        "input_size = len(X_train[0])\n",
        "hidden_size = 6\n",
        "output_size = len(tags)\n",
        "learning_rate = 0.01\n",
        "num_epochs = 987\n",
        "\n",
        "#創建pytorch數據集\n",
        "class ChatDataset(Dataset):\n",
        "    #初始化函式\n",
        "    def __init__(self):\n",
        "        self.n_samples = len(X_train)\n",
        "        self.x_data = X_train\n",
        "        self.y_data = y_train\n",
        "\n",
        "    #用序號取得資料\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    #取得training set大小\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.l1(x))\n",
        "        out = self.relu(self.l2(out))\n",
        "        out = self.l3(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Pytorch神經網路訓練\n",
        "def main():\n",
        "\n",
        "    # 模型、數據集、硬體整合\n",
        "    dataset = ChatDataset()\n",
        "    train_loader  = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = 0.0\n",
        "        for (sentence, tag) in train_loader:\n",
        "            # 梯度歸零\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            sentence = sentence.to(device)\n",
        "            tag = tag.to(dtype=torch.long).to(device)\n",
        "\n",
        "            # 前向傳播(forward propagation)\n",
        "            outputs = model(sentence)\n",
        "            loss = criterion(outputs, tag)\n",
        "\n",
        "            # 反向傳播(backward propagation)\n",
        "            loss.backward()\n",
        "\n",
        "            # 更新所有參數\n",
        "            optimizer.step()\n",
        "\n",
        "        if (epoch+1) % int(num_epochs/10) == 0:\n",
        "            print(f'訓練次數[{epoch+1}/{num_epochs}], 損失函數:{loss.item():.8f}')\n",
        "\n",
        "    print(f'訓練完畢，損失函數為 {loss.item():.4f}')\n",
        "\n",
        "    # 將訓練完的資料、分類器儲存起來，存在data.pth這個檔案裡\n",
        "    data = {\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"input_size\": input_size,\n",
        "    \"hidden_size\": hidden_size,\n",
        "    \"output_size\": output_size,\n",
        "    \"all_words\": all_words,\n",
        "    \"tags\": tags\n",
        "    }\n",
        "    FILE = \"data.pth\"\n",
        "    torch.save(data, FILE)\n",
        "\n",
        "    print(f'以儲存訓練結果檔案至{FILE}')\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    try:\n",
        "        f = open('data.pth','r')\n",
        "        f.close()\n",
        "        tinput = input(\"已讀取到先前使用過的模型，是否要重新訓練(是/否)?  \")\n",
        "        if tinput == \"是\":\n",
        "            print(\"重新訓練新模型\")\n",
        "            file_path = \"data.pth\"\n",
        "            os.remove(file_path)\n",
        "            raise FileNotFoundError\n",
        "    except FileNotFoundError:\n",
        "        main()\n",
        "else:\n",
        "    print(\"__name__ != __main__ !!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na8JSrhdL4R9"
      },
      "source": [
        "## 2.對話"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "LN6jpR0OGusR",
        "outputId": "38926d83-7d1e-4dc8-c09e-de693e28be20"
      },
      "outputs": [],
      "source": [
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
        "model.load_state_dict(model_state)\n",
        "# 將模型從\"訓練模式\"轉換成\"預測模式\"\n",
        "model.eval()\n",
        "\n",
        "#--設計機器人對話--#\n",
        "\n",
        "#機器人名稱與起始招呼語\n",
        "bot_name = \"中文聊天機器人\"\n",
        "print(\"機器人已準備就緒，輸入於終端機即可開始聊天，輸入\\\"quit\\\"結束程式\")\n",
        "\n",
        "while True:\n",
        "    sentence = input(\"You: \")\n",
        "    if sentence == \"quit\":\n",
        "        break\n",
        "\n",
        "    # 處理輸入的語句\n",
        "    sentence = cutwords(sentence)\n",
        "    X = bag_of_words(sentence, all_words)\n",
        "    X = X.reshape(1, X.shape[0])\n",
        "    X = torch.from_numpy(X).to(device)\n",
        "\n",
        "    # 放入模型進行預測\n",
        "    output = model(X)\n",
        "    max_value, predicted = torch.max(output, dim=1)\n",
        "    tag = tags[predicted.item()]\n",
        "\n",
        "    # 指定在橫列中找出最大值\n",
        "    probs = torch.softmax(output, dim=1)\n",
        "    prob = probs[0][predicted.item()]\n",
        "\n",
        "    # 如果預測的可能性大於85%，就從該情境隨機取得一個句子來回覆\n",
        "    if prob.item() > 0.85:\n",
        "        for intent in intents_box['intents_list']:\n",
        "            if tag == intent[\"tag\"]:\n",
        "                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
        "    else:\n",
        "        print(f\"{bot_name}:我不知道你在說甚麼\")\n",
        "    print(f\"\\n最有可能的標籤是 : {tag}， 預測的可能性為: {prob.item()}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
